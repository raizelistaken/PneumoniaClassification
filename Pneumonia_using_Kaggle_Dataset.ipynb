{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "editorial-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import time\n",
    "import functools\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frozen-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-appreciation",
   "metadata": {},
   "source": [
    "# Load in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-indication",
   "metadata": {},
   "source": [
    "A string of thie file path containing the chest x-ray training data is assigned to DATADIR. Within the file path or the two folders. One folder has normal chest xray photos and another folder has chest xrays of people with pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "olive-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = 'C:/Users/Raizel/Desktop/Flatiron/phase1/Project4/PneumoniaClassification/chest_xray/train'\n",
    "CATEGORIES = ['NORMAL', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through all images in the two folders\n",
    "for category in CATEGORIES: \n",
    "    path = os.path.join(DATADIR, category) #joins the images\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img)) #cv2.imread() loads an image\n",
    "        plt.imshow(img_array)\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        DATADIR, \n",
    "        target_size=(224, 224), \n",
    "        batch_size = 5232, \n",
    "        seed = 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split images and labels\n",
    "images, labels = next(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(9):\n",
    "  plt.subplot(330 + 1 + i)\n",
    "  plt.imshow(images[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape labels\n",
    "\n",
    "labels = np.reshape(labels[:,0], (5232,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_model, X_test, y_model, y_test = train_test_split(images, labels, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224,  3)))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = cnn.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_cnn = cnn1.history\n",
    "loss_values = hist_cnn['loss']\n",
    "val_loss_values = hist_cnn['val_loss']\n",
    "acc_values = hist_cnn['acc'] \n",
    "val_acc_values = hist_cnn['val_acc']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = cnn.evaluate(X_train, y_train)\n",
    "results_test = cnn.evaluate(X_test, y_test)\n",
    "print(results_train, results_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
