{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "threatened-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score, roc_curve, auc\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-posting",
   "metadata": {},
   "source": [
    "# Load in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-insertion",
   "metadata": {},
   "source": [
    "The data directories are comprised of the file path strings, one for each train, test, and split. Within the file paths are two folders. One folder has normal chest xray photos (no pneumonia) and another folder has chest xrays of people with pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "divine-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_train = 'C:/Users/Raizel/Desktop/Flatiron/phase1/Project4/PneumoniaClassification/chest_xray/train'\n",
    "datadir_test = 'C:/Users/Raizel/Desktop/Flatiron/phase1/Project4/PneumoniaClassification/chest_xray/test'\n",
    "datadir_validate = 'C:/Users/Raizel/Desktop/Flatiron/phase1/Project4/PneumoniaClassification/chest_xray/val'\n",
    "categories = ['NORMAL', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-associate",
   "metadata": {},
   "source": [
    "# Pneumonia Domain Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-enough",
   "metadata": {},
   "source": [
    "According to the MayoClinic, \"Pneumonia is an infection that inflames the air sacs in one or both lungs.\" People with Pneumonia experience caouing, extreme phlegm, fever, difficulty breathing, and chills. Pneumonia, like many other illness, is very uncomfortable. Using neural networks modeling once can classify an image of a healthy lung compared to the image of a lung of a Pneumonia patient. This way the doctor can learn more about the disease to correctly classify patients as having Pneumonia or not having Pneumonia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-federal",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verified-kansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_train = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        datadir_train, \n",
    "        target_size=(256, 256), \n",
    "        batch_size = 600, \n",
    "        seed = 27,\n",
    "        class_mode=\"binary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stone-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_test = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        datadir_test, \n",
    "        target_size=(256, 256), \n",
    "        batch_size = 624, \n",
    "        seed = 27,\n",
    "        class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "immune-robert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_val = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        datadir_validate, \n",
    "        target_size=(256, 256), \n",
    "        batch_size = 16, \n",
    "        seed = 12,\n",
    "        class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-score",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hawaiian-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(data_train)\n",
    "test_images, test_labels = next(data_test)\n",
    "val_images, val_labels = next(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "existing-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_images)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "X_test = np.array(test_images)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "X_val = np.array(val_images)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (18,12))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.title(categories[int(train_labels[i])], fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-scholar",
   "metadata": {},
   "source": [
    "Since Pneumonia is known to inflame both lungs, I predicted the cloudier images are from Pneumonia patients. https://www.radiologyinfo.org/en/info.cfm?pg=pneumonia says white spots in the lungs is how doctors find an infection from an chest x-ray. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-chemical",
   "metadata": {},
   "source": [
    "# Model One - Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "#matching shape sizes\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['acc', 'Recall', 'Precision'])\n",
    "\n",
    "#history necessary for summary and evaluation\n",
    "history = model.fit(X_train.flatten()[:len(y_train)], y_train,\n",
    "                    batch_size= 1,\n",
    "                    epochs=4,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val.flatten()[:len(y_val)], y_val.flatten()))\n",
    "score = model.evaluate(X_test.flatten()[:len(y_test)], y_test.flatten(), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model.evaluate(X_train.flatten()[:len(y_train)], y_train)\n",
    "results_test = model.evaluate(X_test.flatten()[:len(y_test)], y_test.flatten())\n",
    "print(results_train, results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-graphic",
   "metadata": {},
   "source": [
    "# Evaluation Metrics - Model One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "pred = cnn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, pred.round())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels = ['normal', 'pn'], yticklabels = ['normal', 'pn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-baptist",
   "metadata": {},
   "source": [
    "ex. brain surgeoun trying to move cancer - precsion - being conservative and not moving a lot of cells, just cancerous cells - recall - get rid of more cells assuming cancerous - not leaving positives behind\n",
    "\n",
    "Precision = TP/TP+FP Recall = TP/TP+FN\n",
    "\n",
    "advantages\n",
    "- independent, observations don't imapact each other\n",
    "\n",
    "disadvantages\n",
    "- underfit ---> variance lower , rigid structure - very few parameters - simple model therefore less variance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-banner",
   "metadata": {},
   "source": [
    "There are 75 true negatives (normal images), 371 true positives (pneumonia images), 159 false positives, and 19 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-maintenance",
   "metadata": {},
   "source": [
    "- Precision = TP/TP+FP = ((371)/(371+159)) = .7\n",
    "- Recall = TP/TP+FN  = ((371)/(371+19)) = .95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-separate",
   "metadata": {},
   "source": [
    "The recall is good and the percision is ok (could be a lot better) which means the model didn't precisely differentiate between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-compromise",
   "metadata": {},
   "source": [
    "# Model Two - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "cnn2 = models.Sequential()\n",
    "cnn2.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  3), padding = 'same')) #3 x 3 shape of filter, 64 convolutions\n",
    "cnn2.add(layers.MaxPooling2D((2, 2),padding='same'))\n",
    "cnn2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn2.add(layers.AveragePooling2D((2, 2),padding='same'))\n",
    "cnn2.add(layers.Flatten())\n",
    "cnn2.add(layers.Dense(32, activation='relu'))\n",
    "cnn2.add(layers.Dropout(.5))\n",
    "cnn2.add(layers.Dense(1, activation='sigmoid')) #sigmoid bc classification problem\n",
    "\n",
    "cnn2.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.002),\n",
    "              metrics=['acc', 'Recall', 'Precision', 'AUC'])\n",
    "\n",
    "history = cnn2.fit(X_train,\n",
    "                y_train,\n",
    "                epochs=5,\n",
    "                batch_size=25,\n",
    "                validation_data=(X_val, y_val))\n",
    "toc = time.time()\n",
    "print('run time:', toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = cnn2.evaluate(data_train)\n",
    "results_test = cnn2.evaluate(data_test)\n",
    "print(results_train, results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-samoa",
   "metadata": {},
   "source": [
    "## Evaluation Metrics - Model Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "pred2 = cnn2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, pred2.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, pred2.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels = ['normal', 'pn'], yticklabels = ['normal', 'pn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-independence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-barrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "starting-librarian",
   "metadata": {},
   "source": [
    "# Model Three - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = models.Sequential()\n",
    "cnn3.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  3), padding = 'same')) #3 x 3 shape of filter, 64 convolutions\n",
    "cnn3.add(layers.MaxPooling2D((2, 2),padding='same')) #padding added so edge pixels get included in convolution\n",
    "cnn3.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same')) #hidden layer\n",
    "cnn3.add(layers.MaxPooling2D((2, 2),padding='same')) #max pooling\n",
    "cnn3.add(layers.Flatten()) #flatten layer\n",
    "cnn3.add(layers.Dense(32, activation='relu'))\n",
    "cnn3.add(layers.Dense(1, activation='sigmoid')) #sigmoid bc classification problem\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.007),\n",
    "              metrics=['acc', 'Recall', 'Precision']) #compiling with gradient descent\n",
    "\n",
    "history = cnn3.fit(X_train,\n",
    "                y_train,\n",
    "                epochs=5,\n",
    "                batch_size=25,\n",
    "                validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = cnn3.evaluate(data_train)\n",
    "results_test = cnn3.evaluate(data_test)\n",
    "print(results_train, results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-chuck",
   "metadata": {},
   "source": [
    "## Evaluation Metrics - Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "pred = cnn3.predict(X_test)\n",
    "cm = confusion_matrix(y_test, pred.round())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels = ['normal', 'pn'], yticklabels = ['normal', 'pn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-torture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-handling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-clerk",
   "metadata": {},
   "source": [
    "# Model 4 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "artistic-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "cnn4 = models.Sequential()\n",
    "cnn4.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  3), padding = 'same',strides=2)) #3 x 3 shape of filter, 64 convolutions\n",
    "cnn4.add(layers.AveragePooling2D((2, 2),padding='same',strides=2))\n",
    "cnn4.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same',strides=2))\n",
    "cnn4.add(layers.AveragePooling2D((2, 2),padding='same',strides=2))\n",
    "cnn4.add(layers.Flatten())\n",
    "cnn4.add(layers.Dense(32, activation='relu'))\n",
    "cnn4.add(layers.Dense(1, activation='sigmoid')) #sigmoid bc classification problem\n",
    "\n",
    "cnn4.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.002),\n",
    "              metrics=['acc', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "external-joint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "24/24 [==============================] - 10s 313ms/step - loss: 0.6186 - acc: 0.7349 - recall: 0.9917 - precision: 0.7376 - val_loss: 0.6469 - val_acc: 0.7500 - val_recall: 0.8750 - val_precision: 0.7000\n",
      "Epoch 2/9\n",
      "24/24 [==============================] - 8s 334ms/step - loss: 0.5127 - acc: 0.7582 - recall: 0.9551 - precision: 0.7675 - val_loss: 0.7135 - val_acc: 0.7500 - val_recall: 1.0000 - val_precision: 0.6667\n",
      "Epoch 3/9\n",
      "24/24 [==============================] - 9s 360ms/step - loss: 0.3435 - acc: 0.8473 - recall: 0.9189 - precision: 0.8753 - val_loss: 0.9642 - val_acc: 0.6875 - val_recall: 1.0000 - val_precision: 0.6154\n",
      "Epoch 4/9\n",
      "24/24 [==============================] - 9s 356ms/step - loss: 0.2159 - acc: 0.9146 - recall: 0.9522 - precision: 0.9359 - val_loss: 0.4847 - val_acc: 0.8750 - val_recall: 1.0000 - val_precision: 0.8000\n",
      "Epoch 5/9\n",
      "24/24 [==============================] - 9s 380ms/step - loss: 0.2297 - acc: 0.9268 - recall: 0.9510 - precision: 0.9523 - val_loss: 0.3459 - val_acc: 0.9375 - val_recall: 1.0000 - val_precision: 0.8889\n",
      "Epoch 6/9\n",
      "24/24 [==============================] - 9s 363ms/step - loss: 0.1360 - acc: 0.9460 - recall: 0.9826 - precision: 0.9459 - val_loss: 0.2380 - val_acc: 0.9375 - val_recall: 1.0000 - val_precision: 0.8889\n",
      "Epoch 7/9\n",
      "24/24 [==============================] - 8s 347ms/step - loss: 0.1341 - acc: 0.9611 - recall: 0.9688 - precision: 0.9773 - val_loss: 0.5287 - val_acc: 0.7500 - val_recall: 1.0000 - val_precision: 0.6667\n",
      "Epoch 8/9\n",
      "24/24 [==============================] - 8s 343ms/step - loss: 0.1716 - acc: 0.9363 - recall: 0.9776 - precision: 0.9446 - val_loss: 0.3040 - val_acc: 0.9375 - val_recall: 1.0000 - val_precision: 0.8889\n",
      "Epoch 9/9\n",
      "24/24 [==============================] - 8s 344ms/step - loss: 0.1071 - acc: 0.9709 - recall: 0.9798 - precision: 0.9810 - val_loss: 0.2826 - val_acc: 0.9375 - val_recall: 1.0000 - val_precision: 0.8889\n",
      "run time: 81.31463956832886\n"
     ]
    }
   ],
   "source": [
    "history = cnn4.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=9,\n",
    "                    batch_size=25,\n",
    "                    validation_data=(X_val, y_val))\n",
    "toc = time.time()\n",
    "print('run time:', toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "educated-gothic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        18464     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                262176    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 282,465\n",
      "Trainable params: 282,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "medical-dialogue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 121s 13s/step - loss: 0.1362 - acc: 0.9498 - recall: 0.9548 - precision: 0.9770\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.6351 - acc: 0.7917 - recall: 0.9718 - precision: 0.7610\n",
      "[0.13622213900089264, 0.949769914150238, 0.9548386931419373, 0.977026641368866] [0.6350787281990051, 0.7916666865348816, 0.971794843673706, 0.7610442042350769]\n"
     ]
    }
   ],
   "source": [
    "results_train = cnn4.evaluate(data_train)\n",
    "results_test = cnn4.evaluate(data_test)\n",
    "print(results_train, results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-strength",
   "metadata": {},
   "source": [
    "## Evaluation Metrics - Model 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "spoken-investment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115, 119],\n",
       "       [ 11, 379]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = cnn4.predict(X_test)\n",
    "cm = confusion_matrix(y_test, pred4.round())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "peripheral-store",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.49      0.64       234\\n         1.0       0.76      0.97      0.85       390\\n\\n    accuracy                           0.79       624\\n   macro avg       0.84      0.73      0.75       624\\nweighted avg       0.82      0.79      0.77       624\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, pred4.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "needed-highlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels = ['normal', 'pneumonia'], yticklabels = ['normal', 'pneumonia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-technical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "identified-discrimination",
   "metadata": {},
   "source": [
    "# Model 5 - InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet=inception_v3.InceptionV3(weights='imagenet',include_top=False)\n",
    "imagenet_new=imagenet.output\n",
    "inception_model = models.Sequential()\n",
    "inception_model.add(imagenet)\n",
    "inception_model.add(GlobalAveragePooling2D())\n",
    "inception_model.add(Dense(1024,activation='relu'))\n",
    "inception_model.add(Dense(1024,activation='relu')) #dense layer 2\n",
    "inception_model.add(Dense(512,activation='relu')) #dense layer 3\n",
    "inception_model.add(Dense(1,activation='sigmoid')) #final layer with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy', 'Recall', 'Precision', 'AUC'])\n",
    "\n",
    "inception_model.fit(data_train,\n",
    "          epochs=6,\n",
    "          batch_size=32,\n",
    "          validation_data=(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.evaluate(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_transfer = inception_model.predict(X_test)\n",
    "predictions_transfer = np.around(predictions_transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-photography",
   "metadata": {},
   "source": [
    "## Evaluation Metrics - Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "pred5 = inception_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, pred5.round())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, pred5.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels = ['normal', 'pn'], yticklabels = ['normal', 'pn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-packing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-listing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "possible-individual",
   "metadata": {},
   "source": [
    "# Summary/Business Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-empty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "higher-slovak",
   "metadata": {},
   "source": [
    "# Futher Steps and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-allocation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
