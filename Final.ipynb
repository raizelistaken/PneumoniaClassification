{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "auburn-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score, roc_curve, auc\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-soccer",
   "metadata": {},
   "source": [
    "# Load in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-sunset",
   "metadata": {},
   "source": [
    "The data directories are comprised of the file path strings, one for each train, test, and split. Within the file paths are two folders. One folder has normal chest xray photos (no pneumonia) and another folder has chest xrays of people with pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_train = 'C:/Users/Raizel/Desktop/Flatiron/phase1/Project4/PneumoniaClassification/chest_xray/train'\n",
    "datadir_test = 'C:/Users/Raizel/Desktop/Flatiron/phase1/Project4/PneumoniaClassification/chest_xray/test'\n",
    "datadir_validate = 'C:/Users/Raizel/Desktop/Flatiron/phase1/Project4/PneumoniaClassification/chest_xray/val'\n",
    "categories = ['NORMAL', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-passing",
   "metadata": {},
   "source": [
    "# Pneumonia Domain Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-respondent",
   "metadata": {},
   "source": [
    "According to the MayoClinic, \"Pneumonia is an infection that inflames the air sacs in one or both lungs.\" People with Pneumonia experience caouing, extreme phlegm, fever, difficulty breathing, and chills. Pneumonia, like many other illness, is very uncomfortable. Using neural networks modeling once can classify an image of a healthy lung compared to the image of a lung of a Pneumonia patient. This way the doctor can learn more about the disease to correctly classify patients as having Pneumonia or not having Pneumonia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-kingston",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        datadir_train, \n",
    "        target_size=(256, 256), \n",
    "        batch_size = 600, \n",
    "        seed = 27,\n",
    "        class_mode=\"binary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        datadir_test, \n",
    "        target_size=(256, 256), \n",
    "        batch_size = 624, \n",
    "        seed = 27,\n",
    "        class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        datadir_validate, \n",
    "        target_size=(256, 256), \n",
    "        batch_size = 16, \n",
    "        seed = 12,\n",
    "        class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-beginning",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(data_train)\n",
    "test_images, test_labels = next(data_test)\n",
    "val_images, val_labels = next(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_images)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "X_test = np.array(test_images)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "X_val = np.array(val_images)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (18,12))\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.title(categories[int(train_labels[i])], fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-employer",
   "metadata": {},
   "source": [
    "Since Pneumonia is known to inflame both lungs, I predicted the cloudier images are from Pneumonia patients. https://www.radiologyinfo.org/en/info.cfm?pg=pneumonia says white spots in the lungs is how doctors find an infection from an chest x-ray. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-expansion",
   "metadata": {},
   "source": [
    "# Model One - Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "#matching shape sizes\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['acc', 'Recall', 'Precision'])\n",
    "\n",
    "#history necessary for summary and evaluation\n",
    "history = model.fit(X_train.flatten()[:len(y_train)], y_train,\n",
    "                    batch_size= 1,\n",
    "                    epochs=4,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val.flatten()[:len(y_val)], y_val.flatten()))\n",
    "score = model.evaluate(X_test.flatten()[:len(y_test)], y_test.flatten(), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model.evaluate(X_train.flatten()[:len(y_train)], y_train)\n",
    "results_test = model.evaluate(X_test.flatten()[:len(y_test)], y_test.flatten())\n",
    "print(results_train, results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-founder",
   "metadata": {},
   "source": [
    "# Evaluation Metrics - Model One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "pred = cnn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, pred.round())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels = ['normal', 'pn'], yticklabels = ['normal', 'pn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-vertical",
   "metadata": {},
   "source": [
    "ex. brain surgeoun trying to move cancer - precsion - being conservative and not moving a lot of cells, just cancerous cells - recall - get rid of more cells assuming cancerous - not leaving positives behind\n",
    "\n",
    "Precision = TP/TP+FP Recall = TP/TP+FN\n",
    "\n",
    "advantages\n",
    "- independent, observations don't imapact each other\n",
    "\n",
    "disadvantages\n",
    "- underfit ---> variance lower , rigid structure - very few parameters - simple model therefore less variance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-people",
   "metadata": {},
   "source": [
    "There are 75 true negatives (normal images), 371 true positives (pneumonia images), 159 false positives, and 19 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-ground",
   "metadata": {},
   "source": [
    "- Precision = TP/TP+FP = ((371)/(371+159)) = .7\n",
    "- Recall = TP/TP+FN  = ((371)/(371+19)) = .95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-bunny",
   "metadata": {},
   "source": [
    "The recall is good and the percision is ok (could be a lot better) which means the model didn't precisely differentiate between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-school",
   "metadata": {},
   "source": [
    "# Model Two - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "cnn2 = models.Sequential()\n",
    "cnn2.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  3), padding = 'same')) #3 x 3 shape of filter, 64 convolutions\n",
    "cnn2.add(layers.MaxPooling2D((2, 2),padding='same'))\n",
    "cnn2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn2.add(layers.AveragePooling2D((2, 2),padding='same'))\n",
    "cnn2.add(layers.Flatten())\n",
    "cnn2.add(layers.Dense(32, activation='relu'))\n",
    "cnn2.add(layers.Dropout(.5))\n",
    "cnn2.add(layers.Dense(1, activation='sigmoid')) #sigmoid bc classification problem\n",
    "\n",
    "cnn2.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.002),\n",
    "              metrics=['acc', 'Recall', 'Precision', 'AUC'])\n",
    "\n",
    "history = cnn2.fit(X_train,\n",
    "                y_train,\n",
    "                epochs=5,\n",
    "                batch_size=25,\n",
    "                validation_data=(X_val, y_val))\n",
    "toc = time.time()\n",
    "print('run time:', toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = cnn4.evaluate(data_train)\n",
    "results_test = cnn4.evaluate(data_test)\n",
    "print(results_train, results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-billion",
   "metadata": {},
   "source": [
    "# Evaluation Metrics - Model Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "pred2 = cnn2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, pred2.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels = ['normal', 'pn'], yticklabels = ['normal', 'pn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-community",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-insert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "casual-sugar",
   "metadata": {},
   "source": [
    "# Model Three - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = models.Sequential()\n",
    "cnn3.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  3), padding = 'same')) #3 x 3 shape of filter, 64 convolutions\n",
    "cnn3.add(layers.MaxPooling2D((2, 2),padding='same')) #padding added so edge pixels get included in convolution\n",
    "cnn3.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same')) #hidden layer\n",
    "cnn3.add(layers.MaxPooling2D((2, 2),padding='same')) #max pooling\n",
    "cnn3.add(layers.Flatten()) #flatten layer\n",
    "cnn3.add(layers.Dense(32, activation='relu'))\n",
    "cnn3.add(layers.Dense(1, activation='sigmoid')) #sigmoid bc classification problem\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.007),\n",
    "              metrics=['acc', 'Recall', 'Precision']) #compiling with gradient descent\n",
    "\n",
    "history = cnn3.fit(X_train,\n",
    "                y_train,\n",
    "                epochs=5,\n",
    "                batch_size=25,\n",
    "                validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-paraguay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
